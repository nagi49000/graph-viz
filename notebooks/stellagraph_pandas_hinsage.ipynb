{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reasonable-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipycytoscape as ic  # visualise\n",
    "import pandas as pd\n",
    "import netaddr\n",
    "from stellargraph import StellarGraph\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans  # sanity check embeddings\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "from stellargraph.mapper import HinSAGELinkGenerator\n",
    "from stellargraph.layer import HinSAGE, link_classification\n",
    "from tensorflow import keras\n",
    "from stellargraph.mapper import HinSAGENodeGenerator  # for getting embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-anniversary",
   "metadata": {},
   "source": [
    "### Make some data\n",
    "\n",
    "Create some data in pandas for stellagraph ingestion. Using https://stellargraph.readthedocs.io/en/stable/demos/basics/loading-pandas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "muslim-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cytoscape format\n",
    "data = {'nodes': \n",
    "         [{'data': {'id': 'n0', 'name': 'Node 0', 'ip': '192.168.0.10', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'n1', 'name': 'Node 1', 'ip': '192.168.0.101', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'n2', 'name': 'Node 2', 'ip': '192.168.0.9', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'n3', 'name': 'Node 3', 'ip': '192.168.0.56', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'n4', 'name': 'Node 4', 'ip': '192.168.0.12', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'n5', 'name': 'Node 5', 'ip': '10.0.1.30', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'n6', 'name': 'Node 6', 'ip': '10.0.1.56', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'n7', 'name': 'Node 7', 'ip': '10.0.1.2', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'n8', 'name': 'Node 8', 'ip': '10.0.1.102', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'n9', 'name': 'Node 9', 'ip': '10.0.1.100', 'mask': '255.255.255.0'}},\n",
    "          {'data': {'id': 'nRoot', 'name': 'Node Root', 'id_num': 2011}}\n",
    "         ],\n",
    "        'edges': \n",
    "        [{'data': {'id': 'n0-n5', 'source': 'n0', 'target': 'n5'}},\n",
    "         {'data': {'id': 'n0-n1', 'source': 'n0', 'target': 'n1'}},\n",
    "         {'data': {'id': 'n0-n2', 'source': 'n0', 'target': 'n2'}},\n",
    "         {'data': {'id': 'n0-n8', 'source': 'n0', 'target': 'n8'}},\n",
    "         {'data': {'id': 'n0-n9', 'source': 'n0', 'target': 'n9'}},\n",
    "         {'data': {'id': 'n1-n2', 'source': 'n1', 'target': 'n2'}},\n",
    "         {'data': {'id': 'n8-n9', 'source': 'n8', 'target': 'n9'}},\n",
    "         {'data': {'id': 'n5-n3', 'source': 'n5', 'target': 'n3'}},\n",
    "         {'data': {'id': 'n5-n4', 'source': 'n5', 'target': 'n4'}},\n",
    "         {'data': {'id': 'n5-n6', 'source': 'n5', 'target': 'n6'}},\n",
    "         {'data': {'id': 'n5-n7', 'source': 'n5', 'target': 'n7'}},\n",
    "         {'data': {'id': 'n3-n4', 'source': 'n3', 'target': 'n4'}},\n",
    "         {'data': {'id': 'n6-n7', 'source': 'n6', 'target': 'n7'}},\n",
    "         {'data': {'id': 'nRoot-n1', 'source': 'nRoot', 'target': 'n1'}}]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cooked-exchange",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0</td>\n",
       "      <td>n5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n0</td>\n",
       "      <td>n1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n0</td>\n",
       "      <td>n2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n0</td>\n",
       "      <td>n8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n0</td>\n",
       "      <td>n9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n1</td>\n",
       "      <td>n2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n8</td>\n",
       "      <td>n9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n5</td>\n",
       "      <td>n3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n5</td>\n",
       "      <td>n4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n5</td>\n",
       "      <td>n6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n5</td>\n",
       "      <td>n7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n3</td>\n",
       "      <td>n4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>n6</td>\n",
       "      <td>n7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nRoot</td>\n",
       "      <td>n1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub_tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source target  weight edge_type\n",
       "0      n0     n5     1.0  sub_tree\n",
       "1      n0     n1     1.0  sub_tree\n",
       "2      n0     n2     1.0  sub_tree\n",
       "3      n0     n8     1.0  sub_tree\n",
       "4      n0     n9     1.0  sub_tree\n",
       "5      n1     n2     1.0  sub_tree\n",
       "6      n8     n9     1.0  sub_tree\n",
       "7      n5     n3     1.0  sub_tree\n",
       "8      n5     n4     1.0  sub_tree\n",
       "9      n5     n6     1.0  sub_tree\n",
       "10     n5     n7     1.0  sub_tree\n",
       "11     n3     n4     1.0  sub_tree\n",
       "12     n6     n7     1.0  sub_tree\n",
       "13  nRoot     n1     1.0  sub_tree"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df = pd.DataFrame([x['data'] for x in data['edges']])\n",
    "edges_df = edges_df.drop(['id'], axis=1)\n",
    "edges_df['weight'] = 1.0\n",
    "edges_df['edge_type'] = 'sub_tree'\n",
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "processed-welsh",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nRoot</th>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_num\n",
       "id           \n",
       "nRoot    2011"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_root_df = pd.DataFrame([x['data'] for x in data['nodes'] if 'id_num' in x['data'].keys()])\n",
    "nodes_root_df = nodes_root_df.set_index(['id'])\n",
    "nodes_root_df = nodes_root_df.drop(['name'], axis=1)\n",
    "nodes_root_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-little",
   "metadata": {},
   "source": [
    "StellarGraph only takes node features as a numerical type, so need to cast strings to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nervous-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_num</th>\n",
       "      <th>mask_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n0</th>\n",
       "      <td>3232235530</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n1</th>\n",
       "      <td>3232235621</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n2</th>\n",
       "      <td>3232235529</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n3</th>\n",
       "      <td>3232235576</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n4</th>\n",
       "      <td>3232235532</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n5</th>\n",
       "      <td>167772446</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n6</th>\n",
       "      <td>167772472</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n7</th>\n",
       "      <td>167772418</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n8</th>\n",
       "      <td>167772518</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9</th>\n",
       "      <td>167772516</td>\n",
       "      <td>4294967040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ip_num    mask_num\n",
       "id                        \n",
       "n0  3232235530  4294967040\n",
       "n1  3232235621  4294967040\n",
       "n2  3232235529  4294967040\n",
       "n3  3232235576  4294967040\n",
       "n4  3232235532  4294967040\n",
       "n5   167772446  4294967040\n",
       "n6   167772472  4294967040\n",
       "n7   167772418  4294967040\n",
       "n8   167772518  4294967040\n",
       "n9   167772516  4294967040"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df = pd.DataFrame([x['data'] for x in data['nodes'] if 'ip' in x['data'].keys()])\n",
    "nodes_df = nodes_df.set_index(['id'])\n",
    "\n",
    "networks = [netaddr.IPNetwork(x[0] + '/' + x[1]) for x in zip(nodes_df['ip'], nodes_df['mask'])]\n",
    "nodes_df['ip_num'] = [int(x.ip.bits().replace('.',''), 2) for x in networks]\n",
    "nodes_df['mask_num'] = [int(x.netmask.bits().replace('.',''), 2) for x in networks]\n",
    "nodes_df = nodes_df.drop(['ip', 'mask', 'name'], axis=1)\n",
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "disciplinary-sailing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 11, Edges: 14\n",
      "\n",
      " Node types:\n",
      "  main: [10]\n",
      "    Features: float32 vector, length 2\n",
      "    Edge types: main-sub_tree->main, main-sub_tree->root\n",
      "  root: [1]\n",
      "    Features: float32 vector, length 1\n",
      "    Edge types: root-sub_tree->main\n",
      "\n",
      " Edge types:\n",
      "    main-sub_tree->main: [13]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n",
      "    main-sub_tree->root: [1]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "nodes_edges_sg = StellarGraph(\n",
    "    {'main': nodes_df, 'root': nodes_root_df}, \n",
    "    edges_df,\n",
    "    edge_type_column='edge_type')\n",
    "print(nodes_edges_sg.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-magnet",
   "metadata": {},
   "source": [
    "### HinSAGE\n",
    "\n",
    "Here, we use HinSAGE, which is a variant of GraphSAGE for heterogenous graphs. Follows https://stellargraph.readthedocs.io/en/stable/demos/embeddings/graphsage-unsupervised-sampler-embeddings.html\n",
    "https://stellargraph.readthedocs.io/en/stable/demos/link-prediction/hinsage-link-prediction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-underwear",
   "metadata": {},
   "source": [
    "create a generator that will spit out node pairs that are sampled from the input graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suspended-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(nodes_edges_sg.nodes())\n",
    "number_of_walks = 2\n",
    "length = 3\n",
    "unsupervised_samples = UnsupervisedSampler(\n",
    "    nodes_edges_sg, nodes=nodes, length=length, number_of_walks=number_of_walks\n",
    ")\n",
    "# help(unsupervised_samples)  # generates node pairs with a random binary label. Equal chance of 0 or 1 label. \n",
    "# help(HinSAGELinkGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bright-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_samples = [10, 5]  # sampling from 1-hop and 2-hop in graph\n",
    "generator = HinSAGELinkGenerator(nodes_edges_sg, batch_size, num_samples, head_node_types=['main', 'main'])\n",
    "train_gen = generator.flow(unsupervised_samples)\n",
    "# help(HinSAGE)  # creates a two layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "speaking-stationery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('main', [2, 3]),\n",
       " ('main', [4, 5]),\n",
       " ('main', [6, 7]),\n",
       " ('root', [8]),\n",
       " ('main', [9, 10]),\n",
       " ('root', [11]),\n",
       " ('main', []),\n",
       " ('root', []),\n",
       " ('main', []),\n",
       " ('main', []),\n",
       " ('root', []),\n",
       " ('main', [])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.schema.type_adjacency_list(generator.head_node_types, len(num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "banner-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': [EdgeType(n1='root', rel='sub_tree', n2='main')],\n",
       " 'main': [EdgeType(n1='main', rel='sub_tree', n2='main'),\n",
       "  EdgeType(n1='main', rel='sub_tree', n2='root')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.schema.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-analyst",
   "metadata": {},
   "source": [
    "Create a HinSAGE model, which will have a two layer GCN under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "warming-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [20, 20]  # len(layer_sizes) == len(num_samples). Not sure if len(...) != 2 is supported... \n",
    "                        # depending on using the src or dst node encoders, specifies the dimensionality of the\n",
    "                        # node embeddings\n",
    "hinsage = HinSAGE(\n",
    "    layer_sizes=layer_sizes, generator=generator, bias=True, dropout=0.0, normalize=\"l2\"\n",
    ")\n",
    "# Build the model and expose input and output sockets of hinsage, for node pair inputs:\n",
    "x_inp, x_out = hinsage.in_out_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-leeds",
   "metadata": {},
   "source": [
    "Phrase the 'link prediction problem', which will be predicting the binary label on node pairs coming from unsupervised_samples. Note, the link prediction problem is just a means to an end of computing 2-hop kernel functions over nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sexual-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'ip' method to combine node embeddings into edge embeddings\n"
     ]
    }
   ],
   "source": [
    "# Build the model and expose input and output sockets of hinsage, for node pair inputs:\n",
    "x_inp, x_out = hinsage.in_out_tensors()\n",
    "# build the final layer for training\n",
    "prediction = link_classification(\n",
    "    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    ")(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "final-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec the model for training\n",
    "model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=[keras.metrics.binary_accuracy],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prospective-blast",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0096f4b35be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enqueuer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m     super(KerasSequenceAdapter, self).__init__(\n\u001b[0m\u001b[1;32m    910\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Shuffle is handed in the _make_callable override.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/stellargraph/mapper/sequences.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, batch_num)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# Obtain features for head ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mbatch_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/stellargraph/mapper/sampled_link_generators.py\u001b[0m in \u001b[0;36msample_features\u001b[0;34m(self, head_links, batch_num)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# This requires grouping the sampled nodes by edge type and in order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             nodes_by_type.append(\n\u001b[0;32m--> 471\u001b[0;31m                 [\n\u001b[0m\u001b[1;32m    472\u001b[0m                     (\n\u001b[1;32m    473\u001b[0m                         \u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/stellargraph/mapper/sampled_link_generators.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    472\u001b[0m                     (\n\u001b[1;32m    473\u001b[0m                         \u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                         reduce(\n\u001b[0m\u001b[1;32m    475\u001b[0m                             \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mks\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_samples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_viz_env/lib/python3.8/site-packages/stellargraph/mapper/sampled_link_generators.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    474\u001b[0m                         reduce(\n\u001b[1;32m    475\u001b[0m                             \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                             \u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mks\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_samples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                         ),\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=False,\n",
    "    workers=4,\n",
    "    shuffle=True\n",
    ")\n",
    "# this currently breaks; known bug due to UnsupervisedSampler with HinSAGE\n",
    "# https://github.com/stellargraph/stellargraph/issues/1022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-lotus",
   "metadata": {},
   "source": [
    "Generate some node embeddings from the HinSAGE layer stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp_src = x_inp[0::2]\n",
    "x_out_src = x_out[0]\n",
    "embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-palestinian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_ids = nodes_df.index.values.tolist()\n",
    "node_gen = HinSAGENodeGenerator(nodes_edges_sg, batch_size, num_samples).flow(node_ids)\n",
    "node_embeddings = embedding_model.predict(node_gen, workers=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-tiger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(node_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-charity",
   "metadata": {},
   "source": [
    "Use KMeans to look at embedding clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-uncle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = node_embeddings\n",
    "kmeans = KMeans(n_clusters=4).fit(X)\n",
    "node_to_label = {x:y for x,y in zip(node_ids, kmeans.labels_)}\n",
    "for label in set(kmeans.labels_):\n",
    "    print([x for x, y in node_to_label.items() if y == label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "cytoscapeobj = ic.CytoscapeWidget()\n",
    "cytoscapeobj.graph.add_graph_from_json(data)\n",
    "cytoscapeobj.set_style([{\n",
    "                            'selector': 'node',\n",
    "                            'css': {\n",
    "                                'content': 'data(id)',\n",
    "                                'text-valign': 'center',\n",
    "                                'color': 'black'\n",
    "                            }\n",
    "                        }])\n",
    "display(cytoscapeobj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
